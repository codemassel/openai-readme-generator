# AI-powered README Generator ðŸ¤–
Generiert automatisch komplette READMEs fÃ¼r GitHub-Repositories mit OpenAI / GPT-3.5 API.
![Python](https://img.shields.io/badge/python-3.11-blue)
![OpenAI](https://img.shields.io/badge/OpenAI-API-red)
![Docker](https://img.shields.io/badge/docker-ready-lightgrey)

UnterstÃ¼tzt sowohl **DummyAI** (kostenlos) als auch **OpenAI API**.
Mit **lokalem Cache**, **Docker-Setup** und **FastAPI Webservice**.

---

## Features

* Generiert ein komplettes README fÃ¼r jedes GitHub-Repo
* Lokaler Cache verhindert wiederholte API-Requests
* DummyAI fÃ¼r Entwicklung ohne OpenAI-Quota
* Einfacher Wechsel zu OpenAI fÃ¼r echte README-Generierung
* Dockerized FastAPI-Server fÃ¼r lokale Tests oder Cloud-Deployment

---

## Installation

1. Repository klonen:

```bash
git clone https://github.com/Codemassel/readme-generator.git
cd readme-generator
```

2. Virtuelle Umgebung erstellen (optional, lokal):

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

3. AbhÃ¤ngigkeiten installieren:

```bash
pip install -r requirements.txt
```

4. `.env` Datei erstellen (nicht ins Repo hochladen!):

```
OPENAI_API_KEY=dein_openai_key
```

* DummyAI funktioniert natÃ¼rlich auch ohne `.env`.

---

## CLI Nutzung (lokal)

```bash
python app/main.py
```

* Beachte die Inputs fÃ¼r das auszulesende Repo:

  * GitHub Owner
  * Repo Name
* Ausgabe: `GENERATED_README.md` im Projektordner

---

## FastAPI Webservice

1. Docker Image bauen:

```bash
docker build -t readme-generator .
```

2. Container starten:

```bash
docker run -p 8000:8000 -v ${PWD}/app:/app readme-generator
```

* Zugriff: `http://localhost:8000/docs` (Swagger UI)
* POST `/generate-readme` mit Body:

```json
{
  "owner": "EingegebenerOwner",
  "repo_name": "EingegebensRepo"
}
```

* Antwort: generiertes README

---

## DummyAI vs. OpenAI

* **DummyAI:** Kostenlos, schnell, fÃ¼r Tests und Entwicklung
* **OpenAI:** Nutzt GPT-3.5 oder GPT-4, echtes AI-Generated README
* Umschalten in `app/main.py` oder `app/api.py`:

```python
USE_DUMMY = True  # DummyAI
USE_DUMMY = False # OpenAI API
```

---

## Lokaler Cache

* `cache.json` speichert bereits generierte READMEs
* Verhindert wiederholte API-Requests
* Nicht ins Repo hochladen (`.gitignore`)

---

## Docker-Setup

* Exposed Port: 8000 (lokal) oder anpassen wie gewÃ¼nscht
* Hot-Reload (fÃ¼r Entwicklung):

```dockerfile
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

* Volumes fÃ¼r Hot-Reload:

```bash
docker run -p 8000:8000 -v ${PWD}/app:/app readme-generator
```

---

## Projektstruktur

```
readme-generator/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ ai_generator.py
â”‚   â”œâ”€â”€ dummy_ai.py
â”‚   â”œâ”€â”€ readme_builder.py
â”‚   â”œâ”€â”€ github_client.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ cache_manager.py
â”‚   â””â”€â”€ logging_config.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ cache.json (ignored)
â””â”€â”€ .gitignore
```

---

## .gitignore

```
.env
cache.json
venv/
__pycache__/
*.pyc
```

* Verhindert, dass sensible Daten hochgeladen werden

---

## Zukunft / Erweiterungen

* OpenAI API Key Management in Cloud Secrets
* Remote Deployment (Railway, Render, AWS)
* Weitere AI-Tools integrieren
